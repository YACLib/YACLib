# YACLib
- [github](https://github.com/YACLib/YACLib)
- [documentation](https://yaclib.github.io/YACLib/)

## Мотивация:
YACLib - С++ библиотека для конкурентного и параллельного исполнения задач, которая является альтернативой для существующих решений, стремящаяся к тому, чтобы удовлетворять следующим свойствам:
- Easy to use
- Zero cost abstraction
- Easy to build
- Good test coverage
### Easy to use:
Программировать конкурентные/параллельные программы сложно, поэтому одна из наиболее важных целей, чтобы YACLib было легко использовать правильно.

Пример:

Future в нашем интерфейсе имеет две перегрузки Get:
1. `ReturnValue Get() const &`
2. `ReturnValue Get() &&`

а перегрузки `ReturnValue Get() const &` и `ReturnValue Get() const &&` удалены.

Как следствие - большая часть неправильного или неоптимального использования `Get` обнаруживается на этапе компиляции.
### Zero cost abstraction:
Абстракции, которые предоставляет YACLib должны делать код, оптимально написанный для конкретного случая, проще и оставлять его таким же быстрым.

Например поэтому, `Serial::Execute(...some task...)` - lock-free, а создание и исполнение пайплайна из Future делает ровно одну аллокацию на каждый шаг пайплайна.
### Easy to build:
Сборка YACLib должна быть простой, так как иначе библиотеку сложно добавить в кроссплатформенные проекты. 
При этом сборка не должна значительно замедлять сборку целевого проекта. Поэтому мы собираем весь проект с помощью CMake как статическую библиотеку, стараясь использовать минимум публичного шаблонного кода.

### Good test coverage:
Самое важное - это отсутствие багов. Потому что найти многопоточный баг очень сложно, а если он в библиотеке - еще сложнее.
Поэтому мы:
- стремимся к 100% тестовому покрытию
- тестируем код под множеством платформ с разными флагами сборки
- используем статические анализаторы для С++, такие как clang-tidy, cppcheck
- используем динамические анализаторы для С++, такие как Google Sanitizers, Valgrind, etc

## Что уже сделано:
### Были написаны следующие абстракции:
1. Executors:
    - Inline
    - ThreadPool
    - Serial
2. Future/Promise abstraction
3. Combinators:
    - WhenAll
    - ThreadFactory
    - Documentation, Tests, CI

- ### Inline Executor:
Zero cost абстракция, для того, чтобы избежать лишний проверок `executor` на `nullptr`. Дефолтный `executor` для других классов.

- ### Thread Pool Executor
Абстракция, позволяющая параллельно исполнять задачи на выбранном количестве потоков. Мы написали полезные для пользователя интерфейсы остановки `ThreadPool`, потому что это одна из сложных задач в параллельном программировании:
- `Stop` - запрещает добавлять новые задачи в `ThreadPool`, и выполняет оставшиеся.
- `SoftStop` - вызывает `Stop`, когда в `ThreadPool` не остается задач.
- `HardStop` - вызывает Stop и не выполняет оставшиеся задачи.

Было принято осознанное решение разделить `Join` на `Stop` и `Wait`.

Также была написана почти lock-free специализация `ThreadPool` для одного потока, так как это частый случай использования `ThreadPool` в различных проектах, например: `UIThread, RenderThread, AnimationThread, LoggerThread, FileIOThread etc`.
Во всех этих случаях часто пишут свой велосипед, потому что абстракция `ThreadPool` обычно слишком тяжелое решение для этой задачи, мы же улучшили производительность `ThreadPool` для одного потока, оставив такое же API.
- ### Serial Executor
Абстракция, позволяющая сериализовать исполнение задач поверх `ThreadPool` или другого `Executor`. Это позволяет избавиться от явных блокировок (e.g. `std::mutex`) и перейти к кооперативному исполнению задач.
Наша реализация удовлетворяет нескольким свойствам:
- Полностью lock-free (при этом lock-free имплементация достаточно простая, чтобы быть эффективнее spin-lock)
- Не занимает executor (или его поток, в случае `ThreadPool`) на неограниченное время, позволяя исполняться другим задачам, с помощью перепланирования, вместо рекурсии или цикла.
- Bulk исполнения задач (Batching) - несколько задач исполняются подряд, что позволяет более оптимально использовать кэш процессора.


### Future/Promise/Run abstraction
Абстракция для составления пайплайнов исполнения задач.
```C++
auto thread_pool = executor::MakeThreadPool(4);
auto future = async::Run(thread_pool, task1)
              .Then(task2)
              .Then(task3)
```

Текущая имплементация удовлетворяет следующим свойствам:
- `Promise::Set / Future::Then` - является `lock-free`, реализованным на конечном автомате на атомике
- `Wait/WaitFor/WaitUntil` - не требуют аллокаций, что довольно нетривиально, учитывая первое свойство (отсутствие `std::mutex` и `std::condition_variable` в `SharedState`)
- Одна аллокация на планирование и исполнение каждого шага пайплайна, что является наиболее эффективным решением, помимо `Lazy Future`
- Поддержка `Future<Future<T>> -> Future<T>`

Пример:
```C++

auto future = async::Run(executor::MakeInline(), []{
    return MakeFuture<int>(5); // Returns Future<int>
});

// decltype(future) == Future<int>
```

- Поддерживаем обработку ошибок, как с помощью исключений, так и с помощью кодов возврата (std::error_code)
- Помимо T умеем обрабатывать разные перегрузки: util::Result<T>, std::exception_ptr, std::error_code

Пример:
```C++
auto future = async::Run(executor::MakeInline(), []{
    throw std::runtime_error{"bad exception"};
}).Then([](std::exception_ptr e) { // recover error
    return 1;
});

assert(std::move(future).Get().Value() == 1);
```

### WhenAll Combinator
Абстракция, позволяющая планировать продолжение сразу для набора Futures, переданных через итераторы или как variadic template parameters. Также реализована lock-free.

Пример:
```C++
auto [future1, promise1] = async::MakeContract<int>();
auto [future2, promise2] = async::MakeContract<int>();
auto [future3, promise3] = async::MakeContract<int>();
auto AllFuture = async::WhenAll(future1, future2, future3);
// decltype(AllFuture) == Future<std::array<int, 3>>;
assert(AllFuture.Ready() == false);
promise1.Set(5);
promise2.Set(3);
assert(AllFuture.Ready() == false); // still not completed!
promise2.Set(8);
assert(AllFuture.Ready() == true);

// array{5, 3, 8}:
auto result = std::move(AllFuture).Get().Value(); 
```

### ThreadFactory
Абстракция для удобно создания потоков для разных `ThreadPool`.
Например для задания:
- имени потокам
- приоритета потокам
- колбека на старте исполнения и перед окончанием потока

А также имеется возможность кэширования и переиспользования потоков при использовании `HeavyThreadFactory` и нескольких `ThreadPool`.

## Что планируется сделать
### Lazy Future
Последние несколько лет ключевые члены комитета стандартизации C++ занимаются оптимизацией пайплайна из фьюч на этапе компиляции. (Текущее состояние предложения: [P0443](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p0443r13.html)). Мы хотим реализовать часть этой идеи для оптимизации пайплайна `Futures`. Полностью реализовать предложение крайне сложно, много лучших C++ инженеров занимаются этим несколько лет (среди них Hans Boehm - один из авторов C++ Memory Model, Chris Kohlhoff - создатель Boost.Asio, Erich Niebler - Ranges C++20, Lewis Baker - создатель cppcoro, Gor Nishanov - создатель корутин C++20, etc.). 

Мы хотим реализовать только следующие сценарии:
- Объединять подряд идущие `Future::Then` в одну аллокацию:
```C++
future.Then(task1).Then(task2).Then(task3)
```
- Добавить `lazy::Run`, создание незапущенной Future без аллокации
- Реализация ленивых `Future Combinators` как для `lazy::Future`, так и для `async::Future`
## Разные реализации `ThreadPool` и их бенчмарки
Основной смысл задачи в написании правильный бенчмарков и различных реализаций `ThreadPool` для того, чтобы определить для каких типов задач какой `ThreadPool` наиболее оптимальный.

### План реализации:
- Написать хороший `Test And Set`-spinlock, убедиться, что все остальные алгоритмы spinlock плохо работают в `user-space`
- В дальнейшем если мы используем `std::mutex` - мы также должны сравнивать производительность с использованием `spinlock`
- Реализовать стратегию _Work-Stealing_ и сравнить ее производительность
- Реализовать стратегию _Work-Distribution_ и сравнить ее производительность
- Реализовать _lock-free Michael-Scott queue_ для планирования задач
Подробности см. в [issue](https://github.com/YACLib/YACLib/issues/4) на github


## Fibers
`Fiber`, также известные как: `user level threads`, `stackful coroutines`, `goroutines`, `green threads`. Кооперативная многозадачность полезна во множестве случаев, как правило связанных с `IO-bound` задачами, но не обязательно.

### План реализации:
- Реализовать `Stackful coroutines` (`callable object`, который представляет собой вычисление, которое может останавливаться по собственной воле и возобновляться по воле вызывающего кода или внешнего события).
- Реализовать `Fibers`, по сути являющиеся исполнениями корутин.
- Реализовать `Futex` для `Fibers`, не использующий системных вызовов.
- Реализовать различные примитивы синхронизации для `Fibers`: `Mutex`, `ConditionVariable`, `etc`.
- Реализовать lock-free `AsyncMutex`, по сути переосмысление `executor::Serial`
- Реализовать каналы для передачи данных между `Fibers`: `Bounded/Unbounded SPSC/MPSC/SPMC/MPMC`, стоит попытаться реализовать `lock-free` алгоритмы.
- Реализовать `select` для каналов
Как дополнительную задачу можно рассмотреть реализацию планировщика `Fibers`, аналогичного планировщику `golang` (`kotlin`, `rust tokio` используют такой же алгоритм)
## Concurrent algorithms
Для полноты библиотеки и удобства ее использования, необходимо реализовать следующие абстракции:
- `Shared Future`

Аналог `async::Future`, у которой не константные методы - `thread-safe`
- `Shared Promise`

Аналог `async::Promise`, у которого не константные методы - `thread-safe`
- `WhenAny combinator`

Абстракция, позволяющая планировать продолжение для первой готовой `Future` из набора `Futures`, переданных через итераторы или как variadic template parameters. Реализация должна быть lock-free.
- Попробовать реализовать другие комбинаторы, такие как: `WhenEach`, `WhenSome`, `etc`.
- Для всех комбинаторов реализовать вариант `Wait` (т.е. `WhenAll -> WaitAll`), это экономит аллокацию
## Почему я должен использовать YACLib?
Возможные аналоги:
- STL
- OpenMP
- oneAPI TBB (ранее известная как Intel TBB)
- Boost.Asio
- Folly
- HPX
- Boost.Fiber
- marl
- taskflow
- libunifex/cppcoro

### STL
`future/promise/packaged_task` не являются `zero cost` и обладают _easy to misuse API_.
Также отсутствует возможность для планирования пайплайнов задач.
Другие же примитивы слишком низкоуровневые и подходят скорее для написание собственной библиотеки, например тредпула.

### OpenMP
Хорошо подходит для вычислительных задач, когда нужно быстро попробовать распараллелить код. Однако не подходит для конкурентного исполнения задач, которое на практике встречается значительно чаще.

### oneAPI TBB
Библиотека, которая является более современной и хорошо написанной альтернативой OpenMP. 
Ключевые недостатки:
- Довольно большая библиотека (100 тысяч LOC).
- Обладает весьма специфичным и недружелюбным API для конкурентного исполнения задач.
- В некоторых местах не учитывает протокол когерентности кэшей и не [оптимально](https://github.com/oneapi-src/oneTBB/blob/40a9a1060069d37d5f66912c6ee4cf165144774b/include/oneapi/tbb/spin_mutex.h#L71) использует C++ memory model.

### Boost.Asio
Является хорошей оберткой для network platform specific API. Главный недостаток, что все остальное, не IO, написано скорее как заглушка, предполагающая что у вас есть собственная альтернатива.
### Folly
Хорошая библиотека, которая обладает вполне хорошим и дружелюбным интерфейсом, однако довольно громоздкая, что не удовлетворяет `Easy To Build`. Также в нашей библиотеке мы написали более оптимально:
- `Serial Executor`, сделав его полностью lock-free и удовлетворяющим большему количеству свойств (например, don’t occupy thread)
- Взаимодействие `Future` и `Executor`, уменьшив количество аллокаций, с помощью создания _Callable Shared State_ для `Future`.

### HPX
Гигантская библиотека с очень сложной системой сборки.

### Boost.Fiber и marl
`User Level Threads (Fibers)` - не единственное, что необходимо в библиотеке для конкурентного и параллельного исполнения задач. В частности, Fibers не всегда подходят для CPU-bound задач, например чтобы обрабатывать асинхронные колбеки внешних библиотек. Также в marl отсутствует хороший `user level mutex`, а в Boost.Fiber он не lock-free.

### Taskflow
Видно, что приоритетом библиотеки является распараллеливание задач с помощью CUDA, OpenCL, etc, а не конкурентное исполнение задач.

### libunifex/cppcoro
Обе библиотеки являются довольно инновационными и интересными, но экспериментальными. Полноценная поддержка будет добавлена в STL не раньше, чем в C++23, а наша библиотека планирует поддерживать все стандарты, начиная с C++11.
