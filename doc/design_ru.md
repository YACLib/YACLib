# Дизайн

## Мотивация:

YACLib - С++ библиотека для конкурентного и параллельного исполнения задач,
которая является альтернативой для существующих решений, стремящаяся к тому, чтобы удовлетворять следующим свойствам:

* Easy to use
* Zero cost abstraction
* Easy to build
* Good test coverage

### Easy to use:

Программировать конкурентные/параллельные программы сложно, поэтому одна из наиболее важных целей,
чтобы YACLib было легко использовать правильно.

Пример:

Future в нашем интерфейсе имеет две перегрузки `Get`: `ReturnValue Get() const &` и `ReturnValue Get() &&`,
а перегрузки `ReturnValue Get() &` и `ReturnValue Get() const &&` удалены.

Как следствие - большая часть неправильного или неоптимального использования `Get` обнаруживается на этапе компиляции.

### Zero cost abstraction:

Абстракции, которые предоставляет YACLib должны делать код, оптимально написанный для конкретного случая,
проще и оставлять его таким же быстрым.

Например, поэтому, `Serial::Execute(...some task...)` - lock-free,
а создание и исполнение pipeline из Future делает ровно одну аллокацию на каждый шаг pipeline.

### Easy to build:

Сборка YACLib должна быть простой, так как иначе библиотеку сложно добавить в кроссплатформенные проекты.
При этом сборка не должна значительно замедлять сборку целевого проекта.
Поэтому мы собираем весь проект с помощью CMake как статическую библиотеку,
стараясь использовать минимум публичного шаблонного кода.

### Good test coverage:

Самое важное - это отсутствие багов. Потому что найти многопоточный баг очень сложно, а если он в библиотеке - еще
сложнее. Поэтому мы:

* стремимся к 100% тестовому покрытию
* тестируем код под множеством платформ с разными флагами сборки
* используем статические анализаторы для С++, такие, как clang-tidy, cppcheck
* используем динамические анализаторы для С++, такие, как Google Sanitizers, Valgrind, etc

## Что уже сделано:

### Были написаны следующие абстракции:

1. Executors:
    * Inline
    * ThreadPool
    * Serial
2. Future/Promise abstraction
3. Combinators:
    * WhenAll
    * WhenAny
4. ThreadFactory
5. Documentation, Tests, CI

- ### Inline Executor:

Zero cost абстракция, для того, чтобы избежать лишний проверок `executor` на `nullptr`.

Так же это `executor` по-умолчанию для других классов.

- ### Thread Pool Executor

Абстракция, позволяющая параллельно исполнять задачи на выбранном количестве потоков.
Мы написали полезные для пользователя интерфейсы остановки `ThreadPool`,
потому что это одна из сложных задач в параллельном программировании:

* `Stop` - запрещает добавлять новые задачи в `ThreadPool`, и выполняет оставшиеся.
* `SoftStop` - вызывает `Stop`, когда в `ThreadPool` не остается задач.
* `HardStop` - вызывает Stop и не выполняет оставшиеся задачи.

Было принято осознанное решение разделить `Join` на `Stop` и `Wait`.

Также была написана почти lock-free специализация `ThreadPool` для одного потока, 
так как это частый случай использования `ThreadPool` в различных проектах, 
например: `UIThread, RenderThread, AnimationThread, LoggerThread, FileIOThread etc`.
Во всех этих случаях часто пишут свой велосипед, потому что абстракция `ThreadPool` обычно слишком тяжелое решение для этой задачи,
мы же улучшили производительность `ThreadPool` для одного потока, оставив такое же API.

- ### Serial Executor

Абстракция, позволяющая сериализовать исполнение задач поверх `ThreadPool` или другого `Executor`.
Это позволяет избавиться от явных блокировок (e.g. `std::mutex`) и перейти к кооперативному исполнению задач.

Наша реализация удовлетворяет нескольким свойствам:

* Полностью lock-free (при этом lock-free имплементация достаточно простая, чтобы быть эффективнее spin-lock)
* Не занимает executor (или его поток, в случае `ThreadPool`) на неограниченное время,
  позволяя исполняться другим задачам, с помощью перепланирования, вместо рекурсии или цикла.
* Bulk исполнения задач (Batching) - несколько задач исполняются подряд,
  что позволяет более оптимально использовать кэш процессора.

### Future/Promise/Run abstraction

Абстракция для составления пайплайнов исполнения задач.

```C++
auto thread_pool = MakeThreadPool(4);
auto future = Run(thread_pool, task1)
              .Then(task2)
              .Then(task3)
```

Текущая имплементация удовлетворяет следующим свойствам:

* `Promise::Set / Future::Then` - является `lock-free`, реализованным на конечном автомате на atomic.
* `Wait/WaitFor/WaitUntil` - не требуют аллокаций, что довольно нетривиально, учитывая первое свойство.
  (отсутствие `std::mutex` и `std::condition_variable` в `SharedState`).
* Одна аллокация на планирование и исполнение каждого шага pipeline, что является наиболее эффективным решением,
  помимо `Lazy Future`.
* Поддержка `Future<Future<T>> -> Future<T>`.

Пример:

```C++
auto future = Run(MakeInline(), []{
    return MakeFuture<int>(5); // Returns Future<int>
});

// decltype(future) == Future<int>
```

* Поддерживаем обработку ошибок, как с помощью исключений, так и с помощью кодов возврата (std::error_code)
* Помимо T умеем обрабатывать разные перегрузки: `util::Result<T>`, `std::exception_ptr`, `std::error_code`

Пример:

```C++
auto future = Run(MakeInline(), []{
    throw std::runtime_error{"bad exception"};
}).Then([](std::exception_ptr e) { // recover error
    return 1;
});

assert(std::move(future).Get().Value() == 1);
```

### WhenAll Combinator

Абстракция, позволяющая планировать продолжение сразу для набора Futures, 
переданных через итераторы или как variadic template parameters.
Также реализована lock-free.

Пример:

```C++
auto [future1, promise1] = MakeContract<int>();
auto [future2, promise2] = MakeContract<int>();
auto [future3, promise3] = MakeContract<int>();
auto AllFuture = WhenAll(future1, future2, future3);
// decltype(AllFuture) == Future<std::array<int, 3>>;
assert(AllFuture.Ready() == false);
promise1.Set(5);
promise2.Set(3);
assert(AllFuture.Ready() == false); // still not completed!
promise2.Set(8);
assert(AllFuture.Ready() == true);

// array{5, 3, 8}:
auto result = std::move(AllFuture).Get().Value(); 
```

### ThreadFactory

Абстракция для удобно создания потоков для разных `ThreadPool`. Например, для задания:

* имени потокам
* приоритета потокам
* сallback на старте исполнения и перед окончанием потока

А также имеется возможность кэширования и пере-использования потоков при использовании`HeavyThreadFactory` и нескольких `ThreadPool`.

## Что планируется сделать

### Lazy Future

Последние несколько лет ключевые члены комитета стандартизации C++ занимаются оптимизацией 
pipeline из future на этапе компиляции.
(Текущее состояние предложения: [P0443](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p0443r13.html)).
Мы хотим реализовать часть этой идеи для оптимизации pipeline `Futures`.
Полностью реализовать предложение крайне сложно, много лучших C++ инженеров занимаются этим несколько лет 
(среди них Hans Boehm - один из авторов C++ Memory Model, Chris Kohlhoff - создатель Boost.Asio,
Erich Niebler - Ranges C++20, Lewis Baker - создатель cppcoro, Gor Nishanov - создатель C++20 coroutine, etc.).

Мы хотим реализовать только следующие сценарии:

* Объединять подряд идущие `Future::Then` в одну аллокацию:

```C++
future.Then(task1).Then(task2).Then(task3)
```

* Добавить `lazy::Run`, создание незапущенной Future без аллокации
* Реализация ленивых `Future Combinators` как для `lazy::Future`, так и для `Future`

## Разные реализации ThreadPool и их бенчмарки

Основной смысл задачи в написании правильный бенчмарков и различных реализаций `ThreadPool` для того,
чтобы определить для каких типов задач какой `ThreadPool` наиболее оптимальный.

### План реализации:

* Написать хороший `Test And Set`-spinlock, 
  убедиться, что все остальные алгоритмы spinlock плохо работают в `user-space`.
* В дальнейшем, если мы используем `std::mutex` - мы также должны сравнивать производительность с использованием `spinlock`.
* Реализовать стратегию _Work-Stealing_ и сравнить ее производительность.
* Реализовать стратегию _Work-Distribution_ и сравнить ее производительность.
* Реализовать _lock-free Michael-Scott queue_ для планирования задач.

Подробности см. в [issue](https://github.com/YACLib/YACLib/issues/4) на github.

## Fibers

`Fiber`, также известные как: `user level threads`, `stackful coroutines`, `goroutines`, `green threads`.
Кооперативная многозадачность полезна во множестве случаев, как правило, связанных с `IO-bound` задачами, но не обязательно.

### План реализации:

* Реализовать `Stackful coroutines` (`callable object`, который представляет собой вычисление, которое может
  останавливаться по собственной воле и возобновляться по воле вызывающего кода или внешнего события).
* Реализовать `Fibers`, по сути являющиеся исполнениями coroutine.
* Реализовать `Futex` для `Fibers`, не использующий системных вызовов.
* Реализовать различные примитивы синхронизации для `Fibers`: `Mutex`, `ConditionVariable`, `etc`.
* Реализовать lock-free `AsyncMutex`, по сути переосмысление `Serial`.
* Реализовать каналы для передачи данных между `Fibers`: `Bounded/Unbounded SPSC/MPSC/SPMC/MPMC`, стоит попытаться
  реализовать `lock-free` алгоритмы.
* Реализовать `select` для каналов.

Как дополнительную задачу можно рассмотреть реализацию планировщика `Fibers`, 
аналогичного планировщику `golang` (`kotlin`, `rust tokio` используют такой же алгоритм).

## Concurrent algorithms

Для полноты библиотеки и удобства ее использования, необходимо реализовать следующие абстракции:

- `Shared Future`

Аналог `Future`, у которой не константные методы - `thread-safe`

- `Shared Promise`

Аналог `Promise`, у которого не константные методы - `thread-safe`

- `WhenAny combinator`

Абстракция, позволяющая планировать продолжение для первой готовой `Future` из набора `Futures`, переданных через
итераторы или как variadic template parameters. Реализация должна быть lock-free.

- Попробовать реализовать другие комбинаторы, такие как: `WhenEach`, `WhenSome`, `etc`.
- Для всех комбинаторов реализовать вариант `Wait` (т.е. `WhenAll -> WaitAll`), это экономит аллокацию

## Почему я должен использовать YACLib?

Возможные аналоги:

* STL
* OpenMP
* oneAPI TBB (ранее известная как Intel TBB)
* Boost.Asio
* Folly
* HPX
* Boost.Fiber
* marl
* taskflow
* libunifex/cppcoro

### STL

`future/promise/packaged_task` не являются `zero cost` и обладают _easy to misuse API_.
Также отсутствует возможность для планирования pipeline задач.
Другие же примитивы слишком низкоуровневые и подходят скорее для написания собственной библиотеки, например ThreadPool.

### OpenMP

Хорошо подходит для вычислительных задач, когда нужно быстро попробовать распараллелить код.
Однако не подходит для конкурентного исполнения задач, которое на практике встречается значительно чаще.

### oneAPI TBB

Библиотека, которая является более современной и хорошо написанной альтернативой OpenMP.

Ключевые недостатки:

* Довольно большая библиотека (100 тысяч LOC).
* Обладает весьма специфичным и недружелюбным API для конкурентного исполнения задач.
* В некоторых местах [не учитывает протокол когерентности кэшей и не оптимально использует C++ memory model]
  (https://github.com/oneapi-src/oneTBB/blob/40a9a1060069d37d5f66912c6ee4cf165144774b/include/oneapi/tbb/spin_mutex.h#L71).

### Boost.Asio

Является хорошей оберткой для network platform specific API.
Главный недостаток, что все остальное, не IO, написано скорее как заглушка,
предполагающая, что у вас есть собственная альтернатива.

### Folly

Хорошая библиотека, которая обладает вполне хорошим и дружелюбным интерфейсом, однако довольно громоздкая, что не
удовлетворяет `Easy To Build`. Также в нашей библиотеке мы написали более оптимально:

* `Serial Executor`, сделав его полностью lock-free и удовлетворяющим большему количеству свойств,
  например, don’t occupy thread.
* Взаимодействие `Future` и `Executor`, уменьшив количество аллокаций,
  с помощью создания _Callable Shared State_ для `Future`.

### HPX

Гигантская библиотека с очень сложной системой сборки.

### Boost.Fiber и marl

`User Level Threads (Fibers)` - не единственное,
что необходимо в библиотеке для конкурентного и параллельного исполнения задач.
В частности, Fibers не всегда подходят для CPU-bound задач, например,
чтобы обрабатывать асинхронные callback внешних библиотек.
Также в marl отсутствует хороший `user level mutex`, а в Boost.Fiber он не lock-free.

### Taskflow

Видно, что приоритетом библиотеки является распараллеливание задач с помощью CUDA, OpenCL, etc,
а не конкурентное исполнение задач.

### libunifex/cppcoro

Обе библиотеки являются довольно инновационными и интересными, но экспериментальными.
Полноценная поддержка будет добавлена в STL не раньше, чем в C++23,
а наша библиотека планирует поддерживать все стандарты, начиная с C++11.
